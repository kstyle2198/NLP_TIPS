{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjcVKroQHQmfOfORJvoNHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kstyle2198/NLP_TIPS/blob/main/Building_Language_Models_A_Step_by_Step_BERT_Implementation_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@erkajalkumari/building-language-models-a-step-by-step-bert-implementation-guide-96c9930b9536"
      ],
      "metadata": {
        "id": "huzch3febZiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries & Dataset"
      ],
      "metadata": {
        "id": "X7JWPRsDbggC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3BZOQMGWbUDU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "K7270OKdbWbG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "UQxXcOYJbWYm",
        "outputId": "21b09100-1512-4a03-e26b-82bb08405d08"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cfb7206d-8b1b-413e-9f21-5cdbdac2d7a9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cfb7206d-8b1b-413e-9f21-5cdbdac2d7a9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving financial_data.csv to financial_data (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"financial_data.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzuMQls2bWVr",
        "outputId": "e73eb882-5498-4bde-a275-84f1600b0fee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5842, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [\"text\", \"label\"]\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "RUTKhjzAbWTF",
        "outputId": "462bc7cd-7d31-4e1d-f99a-740c64175499"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  The GeoSolutions technology will leverage Bene...  positive\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5bbd06-e0bb-402f-a384-d406e0900c5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5bbd06-e0bb-402f-a384-d406e0900c5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de5bbd06-e0bb-402f-a384-d406e0900c5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de5bbd06-e0bb-402f-a384-d406e0900c5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86ba85c8-7f88-48d4-8c28-e2cedde3c601\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86ba85c8-7f88-48d4-8c28-e2cedde3c601')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86ba85c8-7f88-48d4-8c28-e2cedde3c601 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKoSL3jVbWQN",
        "outputId": "289f5e2b-38c5-44fd-f37d-222313462f7e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     0.535775\n",
              "positive    0.317015\n",
              "negative    0.147210\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 본 연습 목적상 라벨을 바이너리로"
      ],
      "metadata": {
        "id": "O9vQioR6iNUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"label\"].isin([\"positive\", \"negative\"])]\n",
        "df = df.replace(to_replace=[\"positive\", \"negative\"], value=[0, 1])"
      ],
      "metadata": {
        "id": "m2RZYay7d_G7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Oxsk2yd-1I",
        "outputId": "18d69c73-db24-4643-e420-4d0ce419c223"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.682891\n",
              "1    0.317109\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Dataset into train/test"
      ],
      "metadata": {
        "id": "qhkuTIJ7cbmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label'])\n",
        "train_text.shape, temp_text.shape, train_labels.shape, temp_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFADLxC7bWNh",
        "outputId": "452e82cb-4beb-4dd2-ad66-a946d27dc11d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1898,), (814,), (1898,), (814,))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)\n",
        "val_text.shape, test_text.shape, val_labels.shape, test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ussBxiNRbWKt",
        "outputId": "1e2ea334-dfe6-449e-e20b-b8588a57094e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((407,), (407,), (407,), (407,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import BERT-Base-Uncased"
      ],
      "metadata": {
        "id": "VijN99DrcyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained(model_name)\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Gl204leZcujv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "seq_len[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VeDHwsmc_Al",
        "outputId": "416de2c8-ffb4-4c9b-ced6-1f27baff1c40"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 44, 13, 43, 21]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "tGgDFUMidFvR",
        "outputId": "1b2f5019-677b-44af-cb46-17165a6b365e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGfCAYAAAB1KinVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqrElEQVR4nO3dfVRU953H8c8AwwiJgPjAwwpK0kSTGknUQmiyqUYQ0TUxobs12K1JXW2y6DaSPY3uiRFMz4Gars2a0rg5W7V7Gmrrnmg25pH4gM0WrQ/hGN3Eox6NZgWscQWBOo7M3T9ynHUCAgN3nN/A+3XOPc793d/c+7vfzDCf/ObhOizLsgQAAGCQiFAPAAAA4KsIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOFGBdC4vL9frr7+uTz/9VDExMfrmN7+pn/zkJxozZoyvz6VLl/TMM89o48aNcrvdys/P1y9+8QslJSX5+pw6dUpPPfWUduzYoZtvvlnz5s1TeXm5oqJ6Nhyv16szZ85o8ODBcjgcgZwCAAAIEcuydPHiRaWmpioiops5EisA+fn51vr1661Dhw5ZdXV11owZM6z09HSrpaXF1+fJJ5+00tLSrG3btln79u2z7r33Xuub3/ymb/uVK1escePGWbm5udZHH31kvf3229awYcOsZcuW9Xgcp0+ftiSxsLCwsLCwhOFy+vTpbl/rHZbV+4sF/ulPf9KIESNUU1OjBx54QE1NTRo+fLiqqqr07W9/W5L06aef6o477lBtba3uvfdevfPOO/qrv/ornTlzxjersnbtWj377LP605/+pOjo6G6P29TUpISEBJ0+fVpxcXG+do/Ho/fff1/Tpk2T0+ns7WkNeNTRHtTRHtTRHtTRHtSxb5qbm5WWlqYLFy4oPj6+y74BvcXzVU1NTZKkxMRESdL+/fvl8XiUm5vr6zN27Filp6f7Akptba3uuusuv7d88vPz9dRTT+nw4cO65557OhzH7XbL7Xb71i9evChJiomJUUxMzP+fTFSUYmNjFRMTwwOnD6ijPaijPaijPaijPahj33g8Hknq0cczeh1QvF6vnn76ad13330aN26cJKmhoUHR0dFKSEjw65uUlKSGhgZfn2vDydXtV7d1pry8XGVlZR3a33//fcXGxnZor66uDvh80BF1tAd1tAd1tAd1tAd17J22trYe9+11QCkuLtahQ4f04Ycf9nYXPbZs2TKVlJT41q9OEU2bNq3DWzzV1dXKy8sj2fYBdbQHdbQHdbQHdbQHdeyb5ubmHvftVUBZtGiRtm7dql27dmnkyJG+9uTkZF2+fFkXLlzwm0VpbGxUcnKyr88f//hHv/01Njb6tnXG5XLJ5XJ1aHc6nZ0+QK7XjsBQR3tQR3tQR3tQR3tQx94JpGYB/Q6KZVlatGiRNm/erO3btysjI8Nv+8SJE+V0OrVt2zZf25EjR3Tq1Cnl5ORIknJycvTxxx/r7Nmzvj7V1dWKi4vTnXfeGchwAABAPxXQDEpxcbGqqqr0xhtvaPDgwb7PjMTHxysmJkbx8fGaP3++SkpKlJiYqLi4OC1evFg5OTm69957JUnTpk3TnXfeqb/927/VqlWr1NDQoOeee07FxcWdzpIAAICBJ6CA8sorr0iSJk+e7Ne+fv16Pf7445Kkn/3sZ4qIiFBhYaHfD7VdFRkZqa1bt+qpp55STk6ObrrpJs2bN08rV67s25kAAIB+I6CA0pOfTBk0aJAqKytVWVl53T6jRo3S22+/HcihAQDAAMK1eAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxun1xQLRf4xe+pbfuivS0qosaVzpe3K3d31J7JMVM4M5NADAAMUMCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG4WKB/cRXL/gHAEA4YwYFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgBB5Rdu3Zp1qxZSk1NlcPh0JYtW/y2OxyOTpcXX3zR12f06NEdtldUVPT5ZAAAQP8QcEBpbW1VZmamKisrO91eX1/vt6xbt04Oh0OFhYV+/VauXOnXb/Hixb07AwAA0O9EBXqHgoICFRQUXHd7cnKy3/obb7yhKVOm6JZbbvFrHzx4cIe+1+N2u+V2u33rzc3NkiSPxyOPx+Nrv3r72raBwhVp2bevCMvv364MxFr31EB+PNqJOtqDOtqDOvZNIHVzWJbV61c2h8OhzZs3a/bs2Z1ub2xs1MiRI/WrX/1KRUVFvvbRo0fr0qVL8ng8Sk9PV1FRkZYsWaKoqM7zUmlpqcrKyjq0V1VVKTY2trfDBwAAN1BbW5uKiorU1NSkuLi4LvsGPIMSiF/96lcaPHiwHn30Ub/2f/iHf9CECROUmJioP/zhD1q2bJnq6+u1evXqTvezbNkylZSU+Nabm5uVlpamadOm+Z2gx+NRdXW18vLy5HQ6g3NShhpX+p5t+3JFWHphklfL90XI7XV02fdQab5tx+1vBvLj0U7U0R7U0R7UsW+uvgPSE0ENKOvWrdPcuXM1aNAgv/Zrw8b48eMVHR2tH/zgByovL5fL5eqwH5fL1Wm70+ns9AFyvfb+zN3edZDo1T69jm73O9Dq3BsD8fEYDNTRHtTRHtSxdwKpWdC+Zvz73/9eR44c0d/93d912zc7O1tXrlzRyZMngzUcAAAQRoIWUH75y19q4sSJyszM7LZvXV2dIiIiNGLEiGANBwAAhJGA3+JpaWnRsWPHfOsnTpxQXV2dEhMTlZ6eLunL95g2bdqkf/7nf+5w/9raWu3Zs0dTpkzR4MGDVVtbqyVLlui73/2uhgwZ0odTAQAA/UXAAWXfvn2aMmWKb/3q50nmzZunDRs2SJI2btwoy7L02GOPdbi/y+XSxo0bVVpaKrfbrYyMDC1ZssTvcykAAGBgCzigTJ48Wd19M3nhwoVauHBhp9smTJig3bt3B3pYAAAwgHAtHgAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjRIV6AMCNNnrpW72+78mKmTaOBABwPcygAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYJyAA8quXbs0a9YspaamyuFwaMuWLX7bH3/8cTkcDr9l+vTpfn3Onz+vuXPnKi4uTgkJCZo/f75aWlr6dCIAAKD/CDigtLa2KjMzU5WVldftM336dNXX1/uW3/zmN37b586dq8OHD6u6ulpbt27Vrl27tHDhwsBHDwAA+qWoQO9QUFCggoKCLvu4XC4lJyd3uu2TTz7Ru+++q71792rSpEmSpJdfflkzZszQT3/6U6Wmpna4j9vtltvt9q03NzdLkjwejzwej6/96u1r2wYKV6Rl374iLL9/uxKOte5LrQI534H8eLQTdbQHdbQHdeybQOrmsCyr13+tHQ6HNm/erNmzZ/vaHn/8cW3ZskXR0dEaMmSIHnzwQf34xz/W0KFDJUnr1q3TM888o//93//13efKlSsaNGiQNm3apEceeaTDcUpLS1VWVtahvaqqSrGxsb0dPgAAuIHa2tpUVFSkpqYmxcXFddk34BmU7kyfPl2PPvqoMjIydPz4cf3TP/2TCgoKVFtbq8jISDU0NGjEiBH+g4iKUmJiohoaGjrd57Jly1RSUuJbb25uVlpamqZNm+Z3gh6PR9XV1crLy5PT6bT71Iw2rvQ92/blirD0wiSvlu+LkNvr6LLvodJ82457o/SlVoGc70B+PNqJOtqDOtqDOvbN1XdAesL2gDJnzhzf7bvuukvjx4/Xrbfeqp07d2rq1Km92qfL5ZLL5erQ7nQ6O32AXK+9P3O3dx0kerVPr6Pb/YZjnftSq96c70B8PAYDdbQHdbQHdeydQGoW9K8Z33LLLRo2bJiOHTsmSUpOTtbZs2f9+ly5ckXnz5+/7udWAADAwGL7DMpXff755/riiy+UkpIiScrJydGFCxe0f/9+TZw4UZK0fft2eb1eZWdnB3s4MMjopW+FeggAAEMFHFBaWlp8syGSdOLECdXV1SkxMVGJiYkqKytTYWGhkpOTdfz4cf3oRz/S1772NeXnf/ne/R133KHp06drwYIFWrt2rTwejxYtWqQ5c+Z0+g0eAAAw8AT8Fs++fft0zz336J577pEklZSU6J577tHzzz+vyMhIHTx4UA899JBuv/12zZ8/XxMnTtTvf/97v8+QvPbaaxo7dqymTp2qGTNm6P7779err75q31kBAICwFvAMyuTJk9XVN5Pfe6/7b0gkJiaqqqoq0EMDAIABgmvxAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA40SFegBAOBm99K0e93VFWlqVJY0rfU/udodOVswM4sgAoH9hBgUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAME7AAWXXrl2aNWuWUlNT5XA4tGXLFt82j8ejZ599VnfddZduuukmpaam6nvf+57OnDnjt4/Ro0fL4XD4LRUVFX0+GQAA0D8EHFBaW1uVmZmpysrKDtva2tp04MABLV++XAcOHNDrr7+uI0eO6KGHHurQd+XKlaqvr/ctixcv7t0ZAACAfifgn7ovKChQQUFBp9vi4+NVXV3t1/bzn/9cWVlZOnXqlNLT033tgwcPVnJycqCHBwAAA0DQr8XT1NQkh8OhhIQEv/aKigq98MILSk9PV1FRkZYsWaKoqM6H43a75Xa7fevNzc2SvnxLyePx+Nqv3r62baBwRVr27SvC8vu3K32ptZ1jNtFX6zgQH5d2GMjPaztRR3tQx74JpG4Oy7J6/SrhcDi0efNmzZ49u9Ptly5d0n333aexY8fqtdde87WvXr1aEyZMUGJiov7whz9o2bJleuKJJ7R69epO91NaWqqysrIO7VVVVYqNje3t8AEAwA3U1tamoqIiNTU1KS4ursu+QQsoHo9HhYWF+vzzz7Vz584uB7Ju3Tr94Ac/UEtLi1wuV4ftnc2gpKWl6dy5c3779Xg8qq6uVl5enpxOZ29PKyyNK33Ptn25Iiy9MMmr5fsi5PY6uux7qDS/18exc8wm+mod+1KrgWwgP6/tRB3tQR37prm5WcOGDetRQAnKWzwej0d/8zd/o88++0zbt2/vdhDZ2dm6cuWKTp48qTFjxnTY7nK5Og0uTqez0wfI9dr7M3d710GiV/v0Orrdb1/qHIwxm+hqHQfaY9JuA/F5HQzU0R7UsXcCqZntAeVqODl69Kh27NihoUOHdnufuro6RUREaMSIEXYPBwAAhKGAA0pLS4uOHTvmWz9x4oTq6uqUmJiolJQUffvb39aBAwe0detWtbe3q6GhQZKUmJio6Oho1dbWas+ePZoyZYoGDx6s2tpaLVmyRN/97nc1ZMgQ+84MAACErYADyr59+zRlyhTfeklJiSRp3rx5Ki0t1X/+539Kku6++26/++3YsUOTJ0+Wy+XSxo0bVVpaKrfbrYyMDC1ZssS3HwAAgIADyuTJk9XV52q7+8zthAkTtHv37kAPCwAABhCuxQMAAIxDQAEAAMYhoAAAAOMQUAAAgHGCfi0eAF8avfStXt/3ZMVMG0cCAOZjBgUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgBB5Rdu3Zp1qxZSk1NlcPh0JYtW/y2W5al559/XikpKYqJiVFubq6OHj3q1+f8+fOaO3eu4uLilJCQoPnz56ulpaVPJwIAAPqPgANKa2urMjMzVVlZ2en2VatWac2aNVq7dq327Nmjm266Sfn5+bp06ZKvz9y5c3X48GFVV1dr69at2rVrlxYuXNj7swAAAP1KVKB3KCgoUEFBQafbLMvSSy+9pOeee04PP/ywJOnf//3flZSUpC1btmjOnDn65JNP9O6772rv3r2aNGmSJOnll1/WjBkz9NOf/lSpqal9OB0AANAfBBxQunLixAk1NDQoNzfX1xYfH6/s7GzV1tZqzpw5qq2tVUJCgi+cSFJubq4iIiK0Z88ePfLIIx3263a75Xa7fevNzc2SJI/HI4/H42u/evvatoHCFWnZt68Iy+/frvSl1naO2USB1LE7A/ExfdVAfl7biTragzr2TSB1szWgNDQ0SJKSkpL82pOSknzbGhoaNGLECP9BREUpMTHR1+erysvLVVZW1qH9/fffV2xsbIf26urqXo0/nK3Ksn+fL0zydtvn7bff7vX+gzFmE/Wkjt3pS537i4H4vA4G6mgP6tg7bW1tPe5ra0AJlmXLlqmkpMS33tzcrLS0NE2bNk1xcXG+do/Ho+rqauXl5cnpdIZiqCEzrvQ92/blirD0wiSvlu+LkNvr6LLvodL8Xh/HzjGbKJA6didUde7Lce0ykJ/XdqKO9qCOfXP1HZCesDWgJCcnS5IaGxuVkpLia29sbNTdd9/t63P27Fm/+125ckXnz5/33f+rXC6XXC5Xh3an09npA+R67f2Zu71vL4Cd7tPr6Ha/falzMMZsop7UsTuhqrNJz6OB+LwOBupoD+rYO4HUzNbfQcnIyFBycrK2bdvma2tubtaePXuUk5MjScrJydGFCxe0f/9+X5/t27fL6/UqOzvbzuEAAIAwFfAMSktLi44dO+ZbP3HihOrq6pSYmKj09HQ9/fTT+vGPf6zbbrtNGRkZWr58uVJTUzV79mxJ0h133KHp06drwYIFWrt2rTwejxYtWqQ5c+bwDR4AACCpFwFl3759mjJlim/96mdD5s2bpw0bNuhHP/qRWltbtXDhQl24cEH333+/3n33XQ0aNMh3n9dee02LFi3S1KlTFRERocLCQq1Zs8aG0wEAAP1BwAFl8uTJsqzrf23S4XBo5cqVWrly5XX7JCYmqqqqKtBDAwCAAYJr8QAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjBMV6gEA6J9GL32r1/c9WTHTxpEACEfMoAAAAOMQUAAAgHEIKAAAwDi2B5TRo0fL4XB0WIqLiyVJkydP7rDtySeftHsYAAAgjNn+Idm9e/eqvb3dt37o0CHl5eXpr//6r31tCxYs0MqVK33rsbGxdg8DAACEMdsDyvDhw/3WKyoqdOutt+pb3/qWry02NlbJycl2HxoAAPQTQf2a8eXLl/XrX/9aJSUlcjgcvvbXXntNv/71r5WcnKxZs2Zp+fLlXc6iuN1uud1u33pzc7MkyePxyOPx+Nqv3r62baBwRVr27SvC8vu3K32ptZ1jNlEgdexOqOpswnEH8vPaTtTRHtSxbwKpm8OyrKC9Svzud79TUVGRTp06pdTUVEnSq6++qlGjRik1NVUHDx7Us88+q6ysLL3++uvX3U9paanKyso6tFdVVfH2EAAAYaKtrU1FRUVqampSXFxcl32DGlDy8/MVHR2tN99887p9tm/frqlTp+rYsWO69dZbO+3T2QxKWlqazp0753eCHo9H1dXVysvLk9PptO9EwsC40vds25crwtILk7xavi9Cbq+jy76HSvN7fRw7x2yiQOrYnVDV2YTjDuTntZ2ooz2oY980Nzdr2LBhPQooQXuL57PPPtMHH3zQ5cyIJGVnZ0tSlwHF5XLJ5XJ1aHc6nZ0+QK7X3p+52/v2AtjpPr2ObvfblzoHY8wm6kkduxOqOpt03IH4vA4G6mgP6tg7gdQsaL+Dsn79eo0YMUIzZ3b9k9V1dXWSpJSUlGANBQAAhJmgzKB4vV6tX79e8+bNU1TU/x/i+PHjqqqq0owZMzR06FAdPHhQS5Ys0QMPPKDx48cHYygAACAMBSWgfPDBBzp16pS+//3v+7VHR0frgw8+0EsvvaTW1lalpaWpsLBQzz33XDCGAQAAwlRQAsq0adPU2Wdv09LSVFNTE4xDAgCAfoRr8QAAAOMQUAAAgHEIKAAAwDgEFAAAYJygXosHgRm99K1QDwEAACMwgwIAAIzDDAr6hFkfAEAwMIMCAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcvmYM4Lr4GjmAUGEGBQAAGIeAAgAAjENAAQAAxuEzKACMc+1nX1yRllZlSeNK35O73dHtfU9WzAzm0ADcIMygAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4XIsHCAPXXpsGAAYCZlAAAIBxCCgAAMA4BBQAAGAcPoMCoF/py+d1TlbMtHEkAPqCGRQAAGAc2wNKaWmpHA6H3zJ27Fjf9kuXLqm4uFhDhw7VzTffrMLCQjU2Nto9DAAAEMaCMoPy9a9/XfX19b7lww8/9G1bsmSJ3nzzTW3atEk1NTU6c+aMHn300WAMAwAAhKmgfAYlKipKycnJHdqbmpr0y1/+UlVVVXrwwQclSevXr9cdd9yh3bt369577w3GcAAAQJgJSkA5evSoUlNTNWjQIOXk5Ki8vFzp6enav3+/PB6PcnNzfX3Hjh2r9PR01dbWXjeguN1uud1u33pzc7MkyePxyOPx+Nqv3r62LZy4Iq1QD0GS5Iqw/P5F71BHe9zIOobr346eCPe/j6agjn0TSN0clmXZ+qx/55131NLSojFjxqi+vl5lZWX6n//5Hx06dEhvvvmmnnjiCb+wIUlZWVmaMmWKfvKTn3S6z9LSUpWVlXVor6qqUmxsrJ3DBwAAQdLW1qaioiI1NTUpLi6uy762B5SvunDhgkaNGqXVq1crJiamVwGlsxmUtLQ0nTt3zu8EPR6PqqurlZeXJ6fTGZwTCqJxpe+FegiSvvw/1RcmebV8X4TcXkeohxO2qKM9bmQdD5XmB3X/oRTufx9NQR37prm5WcOGDetRQAn676AkJCTo9ttv17Fjx5SXl6fLly/rwoULSkhI8PVpbGzs9DMrV7lcLrlcrg7tTqez0wfI9dpN524360XM7XUYN6ZwRB3tcSPqGI5/NwIVrn8fTUMdeyeQmgX9d1BaWlp0/PhxpaSkaOLEiXI6ndq2bZtv+5EjR3Tq1Cnl5OQEeygAACBM2D6D8o//+I+aNWuWRo0apTNnzmjFihWKjIzUY489pvj4eM2fP18lJSVKTExUXFycFi9erJycHL7BAwAAfGwPKJ9//rkee+wxffHFFxo+fLjuv/9+7d69W8OHD5ck/exnP1NERIQKCwvldruVn5+vX/ziF3YPAwAAhDHbA8rGjRu73D5o0CBVVlaqsrLS7kMDAIB+gmvxAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4tl+LBwAGotFL3+r1fU9WzLRxJED/wAwKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcfqgNAMJYT38gzhVpaVWWNK70PbnbHZL4gTiYjRkUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG4Vs8NuvLJdcBAMCXmEEBAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxje0ApLy/XN77xDQ0ePFgjRozQ7NmzdeTIEb8+kydPlsPh8FuefPJJu4cCAADClO0BpaamRsXFxdq9e7eqq6vl8Xg0bdo0tba2+vVbsGCB6uvrfcuqVavsHgoAAAhTtv/U/bvvvuu3vmHDBo0YMUL79+/XAw884GuPjY1VcnJyj/bpdrvldrt9683NzZIkj8cjj8fja796+9q2G80VaYXs2HZxRVh+/6J3qKM9bmQd+/K3oy/P/Rtx3M7qGMq/leHKhNeZcBZI3RyWZQX1WX/s2DHddttt+vjjjzVu3DhJX77Fc/jwYVmWpeTkZM2aNUvLly9XbGxsp/soLS1VWVlZh/aqqqrr3gcAAJilra1NRUVFampqUlxcXJd9gxpQvF6vHnroIV24cEEffvihr/3VV1/VqFGjlJqaqoMHD+rZZ59VVlaWXn/99U7309kMSlpams6dO+d3gh6PR9XV1crLy5PT6QzWaXVpXOl7ITmunVwRll6Y5NXyfRFyex2hHk7Yoo72uJF1PFSa3+v7mv7c76yOoTrfvhw31Ex4nQlnzc3NGjZsWI8CSlCvZlxcXKxDhw75hRNJWrhwoe/2XXfdpZSUFE2dOlXHjx/Xrbfe2mE/LpdLLperQ7vT6ez0AXK99hvB3d5/XojcXke/Op9QoY72uBF17MvfjXD5b3xtHUN1vv3hhT2UrzPhLJCaBe1rxosWLdLWrVu1Y8cOjRw5ssu+2dnZkr58OwgAAMD2GRTLsrR48WJt3rxZO3fuVEZGRrf3qaurkySlpKTYPRwAABCGbA8oxcXFqqqq0htvvKHBgweroaFBkhQfH6+YmBgdP35cVVVVmjFjhoYOHaqDBw9qyZIleuCBBzR+/Hi7hwMAAMKQ7QHllVdekfTlN3WutX79ej3++OOKjo7WBx98oJdeekmtra1KS0tTYWGhnnvuObuHAgDowuilb4V6CMB1BeUtnq6kpaWppqbG7sMCAIB+hGvxAAAA4xBQAACAcYL6OygAEE74TAZgDgIKACBs9CVEnqyYaeNIEGy8xQMAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcbhYIADghuKq0egJZlAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHb/EAANCNq988ckVaWpUljSt9T+52R4/ue7JiZjCH1m8xgwIAAIzDDEon+I4+APQ//G0PL8ygAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh68ZAwAQRH35evNA/pE3ZlAAAIBxCCgAAMA4BBQAAGCckH4GpbKyUi+++KIaGhqUmZmpl19+WVlZWaEcEgAA/UY4f/4lZDMov/3tb1VSUqIVK1bowIEDyszMVH5+vs6ePRuqIQEAAEOEbAZl9erVWrBggZ544glJ0tq1a/XWW29p3bp1Wrp0qV9ft9stt9vtW29qapIknT9/Xh6Px9fu8XjU1tamL774Qk6ns9dji7rS2uv79gdRXkttbV5FeSLU7u3Z5cTREXW0B3W0B3W0x42u4xdffNGn+/fl9ayvx+7MxYsXJUmWZXXf2QoBt9ttRUZGWps3b/Zr/973vmc99NBDHfqvWLHCksTCwsLCwsLSD5bTp093mxVCMoNy7tw5tbe3Kykpya89KSlJn376aYf+y5YtU0lJiW/d6/Xq/PnzGjp0qByO/0+wzc3NSktL0+nTpxUXFxe8E+jnqKM9qKM9qKM9qKM9qGPfWJalixcvKjU1tdu+YfFDbS6XSy6Xy68tISHhuv3j4uJ44NiAOtqDOtqDOtqDOtqDOvZefHx8j/qF5EOyw4YNU2RkpBobG/3aGxsblZycHIohAQAAg4QkoERHR2vixInatm2br83r9Wrbtm3KyckJxZAAAIBBQvYWT0lJiebNm6dJkyYpKytLL730klpbW33f6ukNl8ulFStWdHg7CIGhjvagjvagjvagjvagjjeOw7J68l2f4Pj5z3/u+6G2u+++W2vWrFF2dnaohgMAAAwR0oACAADQGa7FAwAAjENAAQAAxiGgAAAA4xBQAACAcfpVQKmsrNTo0aM1aNAgZWdn649//GOoh2S0Xbt2adasWUpNTZXD4dCWLVv8tluWpeeff14pKSmKiYlRbm6ujh49GprBGqq8vFzf+MY3NHjwYI0YMUKzZ8/WkSNH/PpcunRJxcXFGjp0qG6++WYVFhZ2+JFCSK+88orGjx/v+4XOnJwcvfPOO77t1DFwFRUVcjgcevrpp31t1LF7paWlcjgcfsvYsWN926nhjdFvAspvf/tblZSUaMWKFTpw4IAyMzOVn5+vs2fPhnpoxmptbVVmZqYqKys73b5q1SqtWbNGa9eu1Z49e3TTTTcpPz9fly5dusEjNVdNTY2Ki4u1e/duVVdXy+PxaNq0aWpt/f8riC5ZskRvvvmmNm3apJqaGp05c0aPPvpoCEdtppEjR6qiokL79+/Xvn379OCDD+rhhx/W4cOHJVHHQO3du1f/+q//qvHjx/u1U8ee+frXv676+nrf8uGHH/q2UcMbpO/XJjZDVlaWVVxc7Ftvb2+3UlNTrfLy8hCOKnxI8ru6tNfrtZKTk60XX3zR13bhwgXL5XJZv/nNb0IwwvBw9uxZS5JVU1NjWdaXNXM6ndamTZt8fT755BNLklVbWxuqYYaNIUOGWP/2b/9GHQN08eJF67bbbrOqq6utb33rW9YPf/hDy7J4PPbUihUrrMzMzE63UcMbp1/MoFy+fFn79+9Xbm6ury0iIkK5ubmqra0N4cjC14kTJ9TQ0OBX0/j4eGVnZ1PTLjQ1NUmSEhMTJUn79++Xx+Pxq+PYsWOVnp5OHbvQ3t6ujRs3qrW1VTk5OdQxQMXFxZo5c6ZfvSQej4E4evSoUlNTdcstt2ju3Lk6deqUJGp4I4XF1Yy7c+7cObW3tyspKcmvPSkpSZ9++mmIRhXeGhoaJKnTml7dBn9er1dPP/207rvvPo0bN07Sl3WMjo7ucPVt6ti5jz/+WDk5Obp06ZJuvvlmbd68WXfeeafq6uqoYw9t3LhRBw4c0N69ezts4/HYM9nZ2dqwYYPGjBmj+vp6lZWV6S//8i916NAhangD9YuAApiguLhYhw4d8nuvGoEZM2aM6urq1NTUpP/4j//QvHnzVFNTE+phhY3Tp0/rhz/8oaqrqzVo0KBQDydsFRQU+G6PHz9e2dnZGjVqlH73u98pJiYmhCMbWPrFWzzDhg1TZGRkh09RNzY2Kjk5OUSjCm9X60ZNe2bRokXaunWrduzYoZEjR/rak5OTdfnyZV24cMGvP3XsXHR0tL72ta9p4sSJKi8vV2Zmpv7lX/6FOvbQ/v37dfbsWU2YMEFRUVGKiopSTU2N1qxZo6ioKCUlJVHHXkhISNDtt9+uY8eO8Vi8gfpFQImOjtbEiRO1bds2X5vX69W2bduUk5MTwpGFr4yMDCUnJ/vVtLm5WXv27KGm17AsS4sWLdLmzZu1fft2ZWRk+G2fOHGinE6nXx2PHDmiU6dOUcce8Hq9crvd1LGHpk6dqo8//lh1dXW+ZdKkSZo7d67vNnUMXEtLi44fP66UlBQeizdSqD+la5eNGzdaLpfL2rBhg/Xf//3f1sKFC62EhASroaEh1EMz1sWLF62PPvrI+uijjyxJ1urVq62PPvrI+uyzzyzLsqyKigorISHBeuONN6yDBw9aDz/8sJWRkWH9+c9/DvHIzfHUU09Z8fHx1s6dO636+nrf0tbW5uvz5JNPWunp6db27dutffv2WTk5OVZOTk4IR22mpUuXWjU1NdaJEyesgwcPWkuXLrUcDof1/vvvW5ZFHXvr2m/xWBZ17IlnnnnG2rlzp3XixAnrv/7rv6zc3Fxr2LBh1tmzZy3LooY3Sr8JKJZlWS+//LKVnp5uRUdHW1lZWdbu3btDPSSj7dixw5LUYZk3b55lWV9+1Xj58uVWUlKS5XK5rKlTp1pHjhwJ7aAN01n9JFnr16/39fnzn/9s/f3f/701ZMgQKzY21nrkkUes+vr60A3aUN///vetUaNGWdHR0dbw4cOtqVOn+sKJZVHH3vpqQKGO3fvOd75jpaSkWNHR0dZf/MVfWN/5znesY8eO+bZTwxvDYVmWFZq5GwAAgM71i8+gAACA/oWAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADG+T95cCGj/KSp4gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize & Encode the Sequences"
      ],
      "metadata": {
        "id": "UU8aSshtdOH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySMk5nuNdLzh",
        "outputId": "12ac9ffd-7380-4010-ded5-2abda95a0f35"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "J5XfZdG9dSmG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "arCM1zGadUhp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nuCF_TwdVzI",
        "outputId": "4cb45f84-5305-42b2-9cc6-8a1fd807f9d6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5581    1\n",
              "1987    1\n",
              "3442    0\n",
              "3677    1\n",
              "4947    0\n",
              "       ..\n",
              "4126    0\n",
              "1852    0\n",
              "5124    1\n",
              "5041    0\n",
              "2149    0\n",
              "Name: label, Length: 1898, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List to Tensors"
      ],
      "metadata": {
        "id": "wSPrHejAdfUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "YqoCl8u2dXp-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "30anSbE6esRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "sVxhOV_ddhm2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a batch size\n",
        "batch_size = 32\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "1EomQdh_evyu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "uDN_l40_ezY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "FX0Zn_AdexrU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "  def __init__(self, bert):\n",
        "    super(BERT_Arch, self).__init__()\n",
        "    self.bert = bert\n",
        "    # dropout layer\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    # relu activation function\n",
        "    self.relu =  nn.ReLU()\n",
        "    # dense layer 1\n",
        "    self.fc1 = nn.Linear(768,512)\n",
        "    # dense layer 2 (Output layer)   ##### 라벨 개수에 따라 수정해야 하는 부분\n",
        "    self.fc2 = nn.Linear(512,2)\n",
        "    #softmax activation function\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  #define the forward pass\n",
        "  def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "Ny9kCLBte1ew"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Acceleration"
      ],
      "metadata": {
        "id": "KhFjY6CifCpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "-02PHlFlfAAM"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0MO4Rt4fFfc",
        "outputId": "e5ad60fc-a331-49be-fa97-e7c83ccb12af"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8MyjnizfqW3",
        "outputId": "07a0f4a9-4421-4dd3-b434-f5bcb56030e7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에러관련 참고 링크 : https://street-developer.tistory.com/11\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_--cLSFvfHGZ",
        "outputId": "da1fe8cd-2a96-42d5-e3ce-7f07ee3a29f2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.73225309 1.57641196]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)"
      ],
      "metadata": {
        "id": "2M2eYkLbfKLh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "bt7mFi_VhhSx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune"
      ],
      "metadata": {
        "id": "TIldAyFShkXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "ne3MC2IUhjDq"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "            total_loss = total_loss + loss.item()\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            total_preds.append(preds)\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "arMMdw-1hvfH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "Or2LE9-Uh5Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')"
      ],
      "metadata": {
        "id": "2vKFbix0hyIj"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining epochs\n",
        "epochs = 50\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwwS4FKEh8Pb",
        "outputId": "71bee86f-592b-476c-f28b-2f5c5f7e000d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.687\n",
            "Validation Loss: 0.682\n",
            "\n",
            " Epoch 2 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.685\n",
            "Validation Loss: 0.678\n",
            "\n",
            " Epoch 3 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.682\n",
            "Validation Loss: 0.679\n",
            "\n",
            " Epoch 4 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.682\n",
            "Validation Loss: 0.673\n",
            "\n",
            " Epoch 5 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.678\n",
            "Validation Loss: 0.673\n",
            "\n",
            " Epoch 6 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.677\n",
            "Validation Loss: 0.669\n",
            "\n",
            " Epoch 7 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 0.666\n",
            "\n",
            " Epoch 8 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.669\n",
            "Validation Loss: 0.663\n",
            "\n",
            " Epoch 9 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.667\n",
            "Validation Loss: 0.660\n",
            "\n",
            " Epoch 10 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.667\n",
            "Validation Loss: 0.661\n",
            "\n",
            " Epoch 11 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.666\n",
            "Validation Loss: 0.656\n",
            "\n",
            " Epoch 12 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.663\n",
            "Validation Loss: 0.655\n",
            "\n",
            " Epoch 13 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.663\n",
            "Validation Loss: 0.653\n",
            "\n",
            " Epoch 14 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.659\n",
            "Validation Loss: 0.656\n",
            "\n",
            " Epoch 15 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.660\n",
            "Validation Loss: 0.652\n",
            "\n",
            " Epoch 16 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.658\n",
            "Validation Loss: 0.657\n",
            "\n",
            " Epoch 17 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.659\n",
            "Validation Loss: 0.646\n",
            "\n",
            " Epoch 18 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.653\n",
            "Validation Loss: 0.644\n",
            "\n",
            " Epoch 19 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.651\n",
            "Validation Loss: 0.644\n",
            "\n",
            " Epoch 20 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.650\n",
            "Validation Loss: 0.642\n",
            "\n",
            " Epoch 21 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.645\n",
            "Validation Loss: 0.640\n",
            "\n",
            " Epoch 22 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 0.641\n",
            "\n",
            " Epoch 23 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 0.638\n",
            "\n",
            " Epoch 24 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.649\n",
            "Validation Loss: 0.637\n",
            "\n",
            " Epoch 25 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.639\n",
            "Validation Loss: 0.635\n",
            "\n",
            " Epoch 26 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.639\n",
            "Validation Loss: 0.638\n",
            "\n",
            " Epoch 27 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.641\n",
            "Validation Loss: 0.633\n",
            "\n",
            " Epoch 28 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.636\n",
            "Validation Loss: 0.631\n",
            "\n",
            " Epoch 29 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.634\n",
            "Validation Loss: 0.631\n",
            "\n",
            " Epoch 30 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.635\n",
            "Validation Loss: 0.629\n",
            "\n",
            " Epoch 31 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.632\n",
            "Validation Loss: 0.627\n",
            "\n",
            " Epoch 32 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.634\n",
            "Validation Loss: 0.627\n",
            "\n",
            " Epoch 33 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.631\n",
            "Validation Loss: 0.628\n",
            "\n",
            " Epoch 34 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 0.625\n",
            "\n",
            " Epoch 35 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 0.623\n",
            "\n",
            " Epoch 36 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.630\n",
            "Validation Loss: 0.623\n",
            "\n",
            " Epoch 37 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.627\n",
            "Validation Loss: 0.626\n",
            "\n",
            " Epoch 38 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.629\n",
            "Validation Loss: 0.620\n",
            "\n",
            " Epoch 39 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.625\n",
            "Validation Loss: 0.618\n",
            "\n",
            " Epoch 40 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 0.620\n",
            "\n",
            " Epoch 41 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 0.616\n",
            "\n",
            " Epoch 42 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.621\n",
            "Validation Loss: 0.616\n",
            "\n",
            " Epoch 43 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.618\n",
            "Validation Loss: 0.616\n",
            "\n",
            " Epoch 44 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.617\n",
            "Validation Loss: 0.613\n",
            "\n",
            " Epoch 45 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.620\n",
            "Validation Loss: 0.615\n",
            "\n",
            " Epoch 46 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 0.611\n",
            "\n",
            " Epoch 47 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.610\n",
            "\n",
            " Epoch 48 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 0.609\n",
            "\n",
            " Epoch 49 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 0.608\n",
            "\n",
            " Epoch 50 / 50\n",
            "  Batch    50  of     60.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.616\n",
            "Validation Loss: 0.611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML-37AU2h_x9",
        "outputId": "c0f0a110-7b8f-45f3-f661-9621f1da8790"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "j6jV7ITxjIr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "5DqaIfaZjEya"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OiEMx_9jL-1",
        "outputId": "5f8ee015-3251-40fb-df98-8bc628060ecf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.73      0.76       278\n",
            "           1       0.51      0.59      0.54       129\n",
            "\n",
            "    accuracy                           0.69       407\n",
            "   macro avg       0.65      0.66      0.65       407\n",
            "weighted avg       0.70      0.69      0.69       407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "           0       0.73      0.50      0.59       278\n",
        "           1       0.36      0.59      0.44       129\n",
        "\n",
        "    accuracy                           0.53       407\n",
        "   macro avg       0.54      0.55      0.52       407\n",
        "weighted avg       0.61      0.53      0.55       407"
      ],
      "metadata": {
        "id": "ZpoD88C6jYZt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MV1yQLb3jWYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}