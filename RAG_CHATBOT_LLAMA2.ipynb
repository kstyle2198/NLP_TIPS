{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwiZTgTDhlX6GKwzZPpgU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kstyle2198/NLP_TIPS/blob/main/RAG_CHATBOT_LLAMA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faQnxTHSwESG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
        "from loguru import logger\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from llama_cpp import Llama\n",
        "\n",
        "\n",
        "st.set_page_config(layout=\"wide\",page_title=\"llama2\")\n",
        "os.chdir(\"/home/shared/\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####### Session State Variables ####################################\n",
        "if \"file_uploader_key\" not in st.session_state:\n",
        "    st.session_state[\"file_uploader_key\"] = 0\n",
        "\n",
        "if 'questions' not in st.session_state:\n",
        "    st.session_state['questions'] = list()\n",
        "\n",
        "if 'answer' not in st.session_state:\n",
        "    st.session_state['answer'] = list()\n",
        "\n",
        "if 'trans_answer' not in st.session_state:\n",
        "    st.session_state['trans_answer'] = list()\n",
        "\n",
        "if 'src_docu1' not in st.session_state:\n",
        "    st.session_state['src_docu1'] = list()\n",
        "\n",
        "if 'src_meta1' not in st.session_state:\n",
        "    st.session_state['src_meta1'] = list()\n",
        "\n",
        "if 'src_docu2' not in st.session_state:\n",
        "    st.session_state['src_docu2'] = list()\n",
        "\n",
        "if 'src_meta2' not in st.session_state:\n",
        "    st.session_state['src_meta2'] = list()\n",
        "\n",
        "if 'response' not in st.session_state:\n",
        "    st.session_state['response'] = list()\n",
        "\n",
        "if 'text_splitter' not in st.session_state:\n",
        "    st.session_state['text_splitter'] = \"\"\n",
        "\n",
        "if 'embeddings' not in st.session_state:\n",
        "    st.session_state['embeddings'] = \"\"\n",
        "\n",
        "if 'llm' not in st.session_state:\n",
        "    st.session_state['llm'] = \"\"\n",
        "\n",
        "if 'dbqa' not in st.session_state:\n",
        "    st.session_state['dbqa'] = \"\"\n",
        "\n",
        "if 'replied' not in st.session_state:\n",
        "    st.session_state['replied'] = \"\"\n",
        "\n",
        "\n",
        "#### functions ###########################################################\n",
        "\n",
        "@st.cache_data\n",
        "def get_text(docs):\n",
        "    doc_list = []\n",
        "    for doc in docs:\n",
        "        file_name = doc.name  # doc 객체의 이름을 파일 이름으로 사용\n",
        "        with open(file_name, \"wb\") as file:  # 파일을 doc.name으로 저장\n",
        "            file.write(doc.getvalue())\n",
        "            logger.info(f\"Uploaded {file_name}\")\n",
        "        if '.pdf' in doc.name:\n",
        "            loader = PyPDFLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        elif '.docx' in doc.name:\n",
        "            loader = Docx2txtLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        elif '.pptx' in doc.name:\n",
        "            loader = UnstructuredPowerPointLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        doc_list.extend(documents)\n",
        "    return doc_list\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def calculate_time_delta(start_time, end_time):\n",
        "    # Calculate the time difference (time delta) in seconds\n",
        "    time_difference = end_time - start_time\n",
        "    seconds = time_difference.seconds\n",
        "    return seconds\n",
        "\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "class Google_Translator:\n",
        "    def __init__(self):\n",
        "        self.translator = Translator()\n",
        "        self.result = {'src_text': '', 'src_lang': '', 'tgt_text': '', 'tgt_lang': ''}\n",
        "\n",
        "    def translate(self, text, lang='ko'):\n",
        "        translated = self.translator.translate(text, dest=lang)\n",
        "        self.result['src_text'] = translated.origin\n",
        "        self.result['src_lang'] = translated.src\n",
        "        self.result['tgt_text'] = translated.text\n",
        "        self.result['tgt_lang'] = translated.dest\n",
        "\n",
        "        return self.result\n",
        "\n",
        "    def translate_file(self, file_path, lang='ko'):\n",
        "        with open(file_path, 'r') as f:\n",
        "            text = f.read()\n",
        "        return self.translate(text, lang)\n",
        "\n",
        "def trans(en):\n",
        "    translator = Google_Translator()\n",
        "    result = translator.translate(str(en))\n",
        "    if \"tgt_text\" in result.keys():\n",
        "        return result[\"tgt_text\"]\n",
        "    else:\n",
        "        return result[\"src_text\"]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    st.title(\"📑 :red[문서분석 ChatBot] with :blue[LLAMA2] & :green[MISTRAL]\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    with st.expander(\"🎈 **검토 개요**\", expanded=True):\n",
        "        st.markdown('''\n",
        "        - **첨부한 문서에 대해 Q&A 채팅 가능(첨부는 :red[영문 문서]여야 함 / :green[첨부문서 추가, 모델 Temperature, 모델 종류 등 변경시] 모델로딩 버튼 다시 클릭)**\n",
        "        - :red[**🦙Llama2**] 모델 및 :blue[**🪁Mistral**] 모델 선택 가능(8-bit Quantized :blue[CPUs using Llama2-7B, Mistral-7B], C Transformers, and LangChain)\n",
        "        - 한글로 질문해도 응답 하나, 영어로 질문할 때 더 좋은 응답을 제공함 / 질문, 응답, 번역응답, 응답근거, 근거파일를 **csv 파일 형태로 다운로드** 가능\n",
        "        - **[Contact]** 김종배 책임(jongbae.kim@hd.com)\n",
        "        ''')\n",
        "\n",
        "    ##### read uploaded files ####################\n",
        "    uploaded_files = st.file_uploader(\"📚 **검토대상 문서첨부(pdf, docx, pptx)** / 복수 파일 업로드 가능\",type=['pdf','docx', 'pptx'],\n",
        "                                           accept_multiple_files=True, key=st.session_state[\"file_uploader_key\"])\n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "    models = {\"🦙LLAMA2_7B\": \"M_model/llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "             \"🪁MISTRAL_7B\":\"M_model/mistral-7b-instruct-v0.1.Q8_0.gguf\",\n",
        "             \"🦙TinyLlama_1B\":\"M_model/tinyllama-1.1b-chat-v0.3.Q8_0.gguf\"}\n",
        "\n",
        "    model_types = {\"🦙LLAMA2_7B\": \"llama\",\n",
        "                   \"🪁MISTRAL_7B\":\"mistral\",\n",
        "                   \"🦙TinyLlama_1B\":\"llama\"}\n",
        "\n",
        "    col701, col702, col703 = st.columns([3,4,4])\n",
        "    with col701:\n",
        "        sel01 = st.selectbox(\"🚩 **:red[Select LLM(언어모델 선택)]**\", (\"🦙LLAMA2_7B\", \"🪁MISTRAL_7B\", \"🦙TinyLlama_1B\"))\n",
        "        LLM_model = models[sel01]\n",
        "        model_type = model_types[sel01]\n",
        "\n",
        "    with col702:\n",
        "        temp_value = st.slider(\"🌡️ **모델 Temperature :red[(0에 가까우면 보수적, 2에 가까우면 창의적)]**\", min_value=0.0, max_value=2.0, value=0.0, step=0.1)\n",
        "\n",
        "    with col703:\n",
        "        max_token = st.slider(\"🌡️ **Max_New_Token(최대생성가능토큰수)**\", min_value=256, max_value=2000, value=256, step=100)\n",
        "\n",
        "    btn111 = st.button(\"⚙️ 모델로딩\", type='primary')\n",
        "    with st.spinner(\"로딩중...\"):\n",
        "        try:\n",
        "            if btn111==True and uploaded_files != None :\n",
        "\n",
        "                texts = get_text(uploaded_files)\n",
        "\n",
        "                st.session_state['text_splitter'] = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "                docs = st.session_state['text_splitter'].split_documents(texts)\n",
        "                with col1:\n",
        "                    st.info(\"🍉text_splitter 완료\")\n",
        "\n",
        "                st.session_state['embeddings'] = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                                   model_kwargs={'device':'cpu'},)\n",
        "                with col2:\n",
        "                    st.info(\"🍊embeddings 완료\")\n",
        "\n",
        "                vectorstore = FAISS.from_documents(docs, st.session_state['embeddings'])\n",
        "                with col3:\n",
        "                    st.info(\"🍎vectorstore 완료\")\n",
        "\n",
        "                st.session_state['llm'] = CTransformers(model=LLM_model, # Location of downloaded GGML model\n",
        "                                                        model_type=model_type,\n",
        "                                                        stream=True,\n",
        "                                                        config={'max_new_tokens': max_token,\n",
        "                                                                'temperature': temp_value})\n",
        "                with col4:\n",
        "                    st.info(\"🍓LLM 로딩 완료\")\n",
        "\n",
        "                qa_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
        "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "                Context: {context}\n",
        "                Question: {question}\n",
        "\n",
        "                Only return the helpful answer below and nothing else.\n",
        "                Helpful answer:\n",
        "                \"\"\"\n",
        "\n",
        "                prompt = PromptTemplate(template=qa_template, input_variables=['context', 'question'])\n",
        "                st_callback = StreamlitCallbackHandler(st.container())\n",
        "                dbqa = RetrievalQA.from_chain_type(llm=st.session_state['llm'],\n",
        "                                                   chain_type='stuff',\n",
        "                                                   callbacks=[st_callback],\n",
        "                                                   retriever= vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={'k':2}),\n",
        "                                                   return_source_documents=True,\n",
        "                                                   chain_type_kwargs={'prompt': prompt})\n",
        "                st.session_state['dbqa'] = dbqa\n",
        "                with col5:\n",
        "                    st.info(\"🍇RetrievalQA Chain 로딩 완료\")\n",
        "\n",
        "            else:\n",
        "                st.empty()\n",
        "        except:\n",
        "            st.error(\"🚨 검토대상 파일을 첨부해주세요.\")\n",
        "\n",
        "        st.session_state['llm']\n",
        "\n",
        "    tab901, tab902 = st.tabs([\"👔 **개별질의/응답**\", \"🍜 **Bulk질의/응답(:blue[점심시간에 AI 일시키기])**\"])\n",
        "\n",
        "    with tab901:\n",
        "\n",
        "        input100 = st.text_area(\"🖊️ **(파일첨부 및 모델 로딩후) 질문을 입력하세요.**\")\n",
        "\n",
        "        with st.expander(\"**질문 예시**\", expanded=False):\n",
        "            col71, col72, col73 =st.columns(3)\n",
        "            with col71:\n",
        "                st.code(\"what is the main topic of the attached article?\")\n",
        "                st.code(\"what is the main purpose of this document?\")\n",
        "            with col72:\n",
        "                st.code(\"summarize the attached article within 5 lines\")\n",
        "                st.code(\"Are there any risky conditions in the document?\")\n",
        "            with col73:\n",
        "                st.code(\"what is expected in the near future?\")\n",
        "                st.code(\"what is the best suggestion of the document?\")\n",
        "\n",
        "        chk1 = st.checkbox(\"응답 한글 번역 포함\", value=True)\n",
        "        st.session_state['replied'] = st.button(\"⚙️ 질문 제출\", type='primary')\n",
        "\n",
        "\n",
        "        with st.spinner(\"🤗 추론중...\"):\n",
        "            if st.session_state['replied']:\n",
        "                st.session_state['questions'].append(input100)\n",
        "                start_time = datetime.now()\n",
        "\n",
        "                response = st.session_state['dbqa']({'query': input100})\n",
        "                st.session_state['answer'].append(response[\"result\"])\n",
        "                st.session_state['src_docu1'].append(response[\"source_documents\"][0].page_content)\n",
        "                st.session_state['src_meta1'].append(response[\"source_documents\"][0].metadata[\"source\"])\n",
        "                try:\n",
        "                    st.session_state['src_docu2'].append(response[\"source_documents\"][1].page_content)\n",
        "                    st.session_state['src_meta2'].append(response[\"source_documents\"][1].metadata[\"source\"])\n",
        "                except:\n",
        "                    st.session_state['src_docu2'].append(\"\")\n",
        "                    st.session_state['src_meta2'].append(\"\")\n",
        "\n",
        "                st.markdown(f\"😆 :blue[{st.session_state['answer'][-1]}]\")\n",
        "                end_time = datetime.now()\n",
        "                delta = calculate_time_delta(start_time, end_time)\n",
        "                st.warning(f\"⏱️ 추론후 응답소요시간(초) : {delta}\")\n",
        "\n",
        "                try:\n",
        "                    if chk1:\n",
        "                        st.session_state['trans_answer'].append(trans(st.session_state['answer'][-1]))\n",
        "                        st.markdown(f\"😃[번역] :blue[{st.session_state['trans_answer'][-1]}]\")\n",
        "                    else:\n",
        "                        st.session_state['trans_answer'].append(\"\")\n",
        "                except:\n",
        "                    st.session_state['trans_answer'].append(\"\")\n",
        "\n",
        "                end_time = datetime.now()\n",
        "                delta = calculate_time_delta(start_time, end_time)\n",
        "                st.warning(f\"⏱️ 번역후 응답소요시간(초) : {delta}\")\n",
        "\n",
        "            with st.expander(\"✔️ **전체 질의/응답결과 모음 (다운로드)**\", expanded=True):\n",
        "                df = pd.DataFrame({\n",
        "                    \"질문\":st.session_state['questions'],\n",
        "                    \"응답\":st.session_state['answer'],\n",
        "                    \"번역응답\":st.session_state['trans_answer'],\n",
        "                    \"근거문장1\":st.session_state['src_docu1'],\n",
        "                    \"근거파일1\":st.session_state['src_meta1'],\n",
        "                    \"근거문장2\":st.session_state['src_docu2'],\n",
        "                    \"근거파일2\":st.session_state['src_meta2']})\n",
        "                st.dataframe(df, use_container_width=True)\n",
        "\n",
        "\n",
        "                @st.cache_data\n",
        "                def convert_df(df):\n",
        "                    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "                    return df.to_csv().encode('utf-8-sig')\n",
        "\n",
        "                csv = convert_df(df)\n",
        "\n",
        "                st.download_button(\n",
        "                    label=\"🗄️ Download data as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name='answers.csv',\n",
        "                    mime='text/csv',\n",
        "                )\n",
        "    with tab902:\n",
        "        with st.expander(\"**벌크 질의/응답 방법 안내**\", expanded=True):\n",
        "            st.markdown('''\n",
        "            - 질문 첨부 엑셀 파일은 :blue[**.xlsx**] 형식으로 하고, 1행에 :red[**\"질문\" 칼럼명**] 유지 (1열 데이터)\n",
        "            - 아래 응답 추론 버튼 누르면, 질문을 순차적으로 불러와서 응답후 결과를 모아줌 (CSV 파일로 다운로드 가능)\n",
        "            - 한글 번역은 시간당 API 요청 초과시 미실시 될 수 있음 (번역은 LLM이 아니라, 별도 Googletrans API 사용)\n",
        "            - 검토 대상 문서의 사이즈, CPU-base Serving 등으로 추론에 다소간 시간이 소요되는 점 고려, 점심시간 등에 이용 권장(추론시간 단축 방법은 지속 검토중)\n",
        "            ''')\n",
        "            st.image(\"09_개발/김종배_llama2/images/첨부예시이미지.png\", caption=\"엑셀 질문파일 예시 이미지\")\n",
        "\n",
        "        uploaded_file = st.file_uploader(\"질문 목록 엑셀 파일 첨부\")\n",
        "        if uploaded_file is not None:\n",
        "            t_df = pd.read_excel(uploaded_file)\n",
        "            질문목록 = t_df[\"질문\"]\n",
        "            질문개수 = len(질문목록)\n",
        "            st.markdown(f\"🎈 **입력 질문 목록 / :green[총 질문개수 :{질문개수}개]**\")\n",
        "            st.dataframe(질문목록, use_container_width=True)\n",
        "\n",
        "        btn999= st.button(\"🔍 Bulk 응답 추론\", type=\"primary\")\n",
        "        with st.spinner(\"벌크 응답 추론중...\"):\n",
        "            if btn999:\n",
        "\n",
        "                for idx, 질문 in enumerate(질문목록):\n",
        "                    time.sleep(1)\n",
        "                    st.markdown(f\"[질문{idx+1}] {질문}\")\n",
        "                    st.session_state['questions'].append(질문)\n",
        "                    start_time = datetime.now()\n",
        "                    start_time\n",
        "\n",
        "                    response = st.session_state['dbqa']({'query': 질문})\n",
        "\n",
        "                    st.session_state['answer'].append(response[\"result\"])\n",
        "                    st.session_state['src_docu1'].append(response[\"source_documents\"][0].page_content)\n",
        "                    st.session_state['src_meta1'].append(response[\"source_documents\"][0].metadata[\"source\"])\n",
        "                    st.session_state['src_docu2'].append(response[\"source_documents\"][1].page_content)\n",
        "                    st.session_state['src_meta2'].append(response[\"source_documents\"][1].metadata[\"source\"])\n",
        "\n",
        "                    st.markdown(f\"😆 :blue[{st.session_state['answer'][-1]}]\")\n",
        "\n",
        "                    try:\n",
        "                        if chk1:\n",
        "                            st.session_state['trans_answer'].append(trans3(st.session_state['answer'][-1]))\n",
        "                            st.markdown(f\"😃[번역] :blue[{st.session_state['trans_answer'][-1]}]\")\n",
        "                        else:\n",
        "                            st.session_state['trans_answer'].append(\"\")\n",
        "                    except:\n",
        "                        st.session_state['trans_answer'].append(\"\")\n",
        "\n",
        "                    end_time = datetime.now()\n",
        "                    delta = calculate_time_delta(start_time, end_time)\n",
        "                    st.warning(f\"⏱️ 응답소요시간(초) : {delta}\")\n",
        "\n",
        "                with st.expander(\"✔️ **전체 질의/응답결과 모음 (다운로드)**\", expanded=True):\n",
        "                    df = pd.DataFrame({\n",
        "                        \"질문\":st.session_state['questions'],\n",
        "                        \"응답\":st.session_state['answer'],\n",
        "                        \"번역응답\":st.session_state['trans_answer'],\n",
        "                        \"근거문장1\":st.session_state['src_docu1'],\n",
        "                        \"근거파일1\":st.session_state['src_meta1'],\n",
        "                        \"근거문장2\":st.session_state['src_docu2'],\n",
        "                        \"근거파일2\":st.session_state['src_meta2']})\n",
        "                    st.dataframe(df, use_container_width=True)\n",
        "\n",
        "\n",
        "                    @st.cache_data\n",
        "                    def convert_df(df):\n",
        "                        # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "                        return df.to_csv().encode('utf-8-sig')\n",
        "\n",
        "                    csv = convert_df(df)\n",
        "\n",
        "                    st.download_button(\n",
        "                        label=\"🗄️ Download data as CSV\",\n",
        "                        data=csv,\n",
        "                        file_name='bulk_answers.csv',\n",
        "                        mime='text/csv',\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}