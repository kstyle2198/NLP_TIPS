{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwiZTgTDhlX6GKwzZPpgU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kstyle2198/NLP_TIPS/blob/main/RAG_CHATBOT_LLAMA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faQnxTHSwESG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
        "from loguru import logger\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.callbacks import StreamlitCallbackHandler\n",
        "from llama_cpp import Llama\n",
        "\n",
        "\n",
        "st.set_page_config(layout=\"wide\",page_title=\"llama2\")\n",
        "os.chdir(\"/home/shared/\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####### Session State Variables ####################################\n",
        "if \"file_uploader_key\" not in st.session_state:\n",
        "    st.session_state[\"file_uploader_key\"] = 0\n",
        "\n",
        "if 'questions' not in st.session_state:\n",
        "    st.session_state['questions'] = list()\n",
        "\n",
        "if 'answer' not in st.session_state:\n",
        "    st.session_state['answer'] = list()\n",
        "\n",
        "if 'trans_answer' not in st.session_state:\n",
        "    st.session_state['trans_answer'] = list()\n",
        "\n",
        "if 'src_docu1' not in st.session_state:\n",
        "    st.session_state['src_docu1'] = list()\n",
        "\n",
        "if 'src_meta1' not in st.session_state:\n",
        "    st.session_state['src_meta1'] = list()\n",
        "\n",
        "if 'src_docu2' not in st.session_state:\n",
        "    st.session_state['src_docu2'] = list()\n",
        "\n",
        "if 'src_meta2' not in st.session_state:\n",
        "    st.session_state['src_meta2'] = list()\n",
        "\n",
        "if 'response' not in st.session_state:\n",
        "    st.session_state['response'] = list()\n",
        "\n",
        "if 'text_splitter' not in st.session_state:\n",
        "    st.session_state['text_splitter'] = \"\"\n",
        "\n",
        "if 'embeddings' not in st.session_state:\n",
        "    st.session_state['embeddings'] = \"\"\n",
        "\n",
        "if 'llm' not in st.session_state:\n",
        "    st.session_state['llm'] = \"\"\n",
        "\n",
        "if 'dbqa' not in st.session_state:\n",
        "    st.session_state['dbqa'] = \"\"\n",
        "\n",
        "if 'replied' not in st.session_state:\n",
        "    st.session_state['replied'] = \"\"\n",
        "\n",
        "\n",
        "#### functions ###########################################################\n",
        "\n",
        "@st.cache_data\n",
        "def get_text(docs):\n",
        "    doc_list = []\n",
        "    for doc in docs:\n",
        "        file_name = doc.name  # doc ê°ì²´ì˜ ì´ë¦„ì„ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©\n",
        "        with open(file_name, \"wb\") as file:  # íŒŒì¼ì„ doc.nameìœ¼ë¡œ ì €ì¥\n",
        "            file.write(doc.getvalue())\n",
        "            logger.info(f\"Uploaded {file_name}\")\n",
        "        if '.pdf' in doc.name:\n",
        "            loader = PyPDFLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        elif '.docx' in doc.name:\n",
        "            loader = Docx2txtLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        elif '.pptx' in doc.name:\n",
        "            loader = UnstructuredPowerPointLoader(file_name)\n",
        "            documents = loader.load_and_split()\n",
        "        doc_list.extend(documents)\n",
        "    return doc_list\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def calculate_time_delta(start_time, end_time):\n",
        "    # Calculate the time difference (time delta) in seconds\n",
        "    time_difference = end_time - start_time\n",
        "    seconds = time_difference.seconds\n",
        "    return seconds\n",
        "\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "class Google_Translator:\n",
        "    def __init__(self):\n",
        "        self.translator = Translator()\n",
        "        self.result = {'src_text': '', 'src_lang': '', 'tgt_text': '', 'tgt_lang': ''}\n",
        "\n",
        "    def translate(self, text, lang='ko'):\n",
        "        translated = self.translator.translate(text, dest=lang)\n",
        "        self.result['src_text'] = translated.origin\n",
        "        self.result['src_lang'] = translated.src\n",
        "        self.result['tgt_text'] = translated.text\n",
        "        self.result['tgt_lang'] = translated.dest\n",
        "\n",
        "        return self.result\n",
        "\n",
        "    def translate_file(self, file_path, lang='ko'):\n",
        "        with open(file_path, 'r') as f:\n",
        "            text = f.read()\n",
        "        return self.translate(text, lang)\n",
        "\n",
        "def trans(en):\n",
        "    translator = Google_Translator()\n",
        "    result = translator.translate(str(en))\n",
        "    if \"tgt_text\" in result.keys():\n",
        "        return result[\"tgt_text\"]\n",
        "    else:\n",
        "        return result[\"src_text\"]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    st.title(\"ğŸ“‘ :red[ë¬¸ì„œë¶„ì„ ChatBot] with :blue[LLAMA2] & :green[MISTRAL]\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    with st.expander(\"ğŸˆ **ê²€í†  ê°œìš”**\", expanded=True):\n",
        "        st.markdown('''\n",
        "        - **ì²¨ë¶€í•œ ë¬¸ì„œì— ëŒ€í•´ Q&A ì±„íŒ… ê°€ëŠ¥(ì²¨ë¶€ëŠ” :red[ì˜ë¬¸ ë¬¸ì„œ]ì—¬ì•¼ í•¨ / :green[ì²¨ë¶€ë¬¸ì„œ ì¶”ê°€, ëª¨ë¸ Temperature, ëª¨ë¸ ì¢…ë¥˜ ë“± ë³€ê²½ì‹œ] ëª¨ë¸ë¡œë”© ë²„íŠ¼ ë‹¤ì‹œ í´ë¦­)**\n",
        "        - :red[**ğŸ¦™Llama2**] ëª¨ë¸ ë° :blue[**ğŸªMistral**] ëª¨ë¸ ì„ íƒ ê°€ëŠ¥(8-bit Quantized :blue[CPUs using Llama2-7B, Mistral-7B], C Transformers, and LangChain)\n",
        "        - í•œê¸€ë¡œ ì§ˆë¬¸í•´ë„ ì‘ë‹µ í•˜ë‚˜, ì˜ì–´ë¡œ ì§ˆë¬¸í•  ë•Œ ë” ì¢‹ì€ ì‘ë‹µì„ ì œê³µí•¨ / ì§ˆë¬¸, ì‘ë‹µ, ë²ˆì—­ì‘ë‹µ, ì‘ë‹µê·¼ê±°, ê·¼ê±°íŒŒì¼ë¥¼ **csv íŒŒì¼ í˜•íƒœë¡œ ë‹¤ìš´ë¡œë“œ** ê°€ëŠ¥\n",
        "        - **[Contact]** ê¹€ì¢…ë°° ì±…ì„(jongbae.kim@hd.com)\n",
        "        ''')\n",
        "\n",
        "    ##### read uploaded files ####################\n",
        "    uploaded_files = st.file_uploader(\"ğŸ“š **ê²€í† ëŒ€ìƒ ë¬¸ì„œì²¨ë¶€(pdf, docx, pptx)** / ë³µìˆ˜ íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥\",type=['pdf','docx', 'pptx'],\n",
        "                                           accept_multiple_files=True, key=st.session_state[\"file_uploader_key\"])\n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "\n",
        "    models = {\"ğŸ¦™LLAMA2_7B\": \"M_model/llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "             \"ğŸªMISTRAL_7B\":\"M_model/mistral-7b-instruct-v0.1.Q8_0.gguf\",\n",
        "             \"ğŸ¦™TinyLlama_1B\":\"M_model/tinyllama-1.1b-chat-v0.3.Q8_0.gguf\"}\n",
        "\n",
        "    model_types = {\"ğŸ¦™LLAMA2_7B\": \"llama\",\n",
        "                   \"ğŸªMISTRAL_7B\":\"mistral\",\n",
        "                   \"ğŸ¦™TinyLlama_1B\":\"llama\"}\n",
        "\n",
        "    col701, col702, col703 = st.columns([3,4,4])\n",
        "    with col701:\n",
        "        sel01 = st.selectbox(\"ğŸš© **:red[Select LLM(ì–¸ì–´ëª¨ë¸ ì„ íƒ)]**\", (\"ğŸ¦™LLAMA2_7B\", \"ğŸªMISTRAL_7B\", \"ğŸ¦™TinyLlama_1B\"))\n",
        "        LLM_model = models[sel01]\n",
        "        model_type = model_types[sel01]\n",
        "\n",
        "    with col702:\n",
        "        temp_value = st.slider(\"ğŸŒ¡ï¸ **ëª¨ë¸ Temperature :red[(0ì— ê°€ê¹Œìš°ë©´ ë³´ìˆ˜ì , 2ì— ê°€ê¹Œìš°ë©´ ì°½ì˜ì )]**\", min_value=0.0, max_value=2.0, value=0.0, step=0.1)\n",
        "\n",
        "    with col703:\n",
        "        max_token = st.slider(\"ğŸŒ¡ï¸ **Max_New_Token(ìµœëŒ€ìƒì„±ê°€ëŠ¥í† í°ìˆ˜)**\", min_value=256, max_value=2000, value=256, step=100)\n",
        "\n",
        "    btn111 = st.button(\"âš™ï¸ ëª¨ë¸ë¡œë”©\", type='primary')\n",
        "    with st.spinner(\"ë¡œë”©ì¤‘...\"):\n",
        "        try:\n",
        "            if btn111==True and uploaded_files != None :\n",
        "\n",
        "                texts = get_text(uploaded_files)\n",
        "\n",
        "                st.session_state['text_splitter'] = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "                docs = st.session_state['text_splitter'].split_documents(texts)\n",
        "                with col1:\n",
        "                    st.info(\"ğŸ‰text_splitter ì™„ë£Œ\")\n",
        "\n",
        "                st.session_state['embeddings'] = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                                   model_kwargs={'device':'cpu'},)\n",
        "                with col2:\n",
        "                    st.info(\"ğŸŠembeddings ì™„ë£Œ\")\n",
        "\n",
        "                vectorstore = FAISS.from_documents(docs, st.session_state['embeddings'])\n",
        "                with col3:\n",
        "                    st.info(\"ğŸvectorstore ì™„ë£Œ\")\n",
        "\n",
        "                st.session_state['llm'] = CTransformers(model=LLM_model, # Location of downloaded GGML model\n",
        "                                                        model_type=model_type,\n",
        "                                                        stream=True,\n",
        "                                                        config={'max_new_tokens': max_token,\n",
        "                                                                'temperature': temp_value})\n",
        "                with col4:\n",
        "                    st.info(\"ğŸ“LLM ë¡œë”© ì™„ë£Œ\")\n",
        "\n",
        "                qa_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
        "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "                Context: {context}\n",
        "                Question: {question}\n",
        "\n",
        "                Only return the helpful answer below and nothing else.\n",
        "                Helpful answer:\n",
        "                \"\"\"\n",
        "\n",
        "                prompt = PromptTemplate(template=qa_template, input_variables=['context', 'question'])\n",
        "                st_callback = StreamlitCallbackHandler(st.container())\n",
        "                dbqa = RetrievalQA.from_chain_type(llm=st.session_state['llm'],\n",
        "                                                   chain_type='stuff',\n",
        "                                                   callbacks=[st_callback],\n",
        "                                                   retriever= vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={'k':2}),\n",
        "                                                   return_source_documents=True,\n",
        "                                                   chain_type_kwargs={'prompt': prompt})\n",
        "                st.session_state['dbqa'] = dbqa\n",
        "                with col5:\n",
        "                    st.info(\"ğŸ‡RetrievalQA Chain ë¡œë”© ì™„ë£Œ\")\n",
        "\n",
        "            else:\n",
        "                st.empty()\n",
        "        except:\n",
        "            st.error(\"ğŸš¨ ê²€í† ëŒ€ìƒ íŒŒì¼ì„ ì²¨ë¶€í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "        st.session_state['llm']\n",
        "\n",
        "    tab901, tab902 = st.tabs([\"ğŸ‘” **ê°œë³„ì§ˆì˜/ì‘ë‹µ**\", \"ğŸœ **Bulkì§ˆì˜/ì‘ë‹µ(:blue[ì ì‹¬ì‹œê°„ì— AI ì¼ì‹œí‚¤ê¸°])**\"])\n",
        "\n",
        "    with tab901:\n",
        "\n",
        "        input100 = st.text_area(\"ğŸ–Šï¸ **(íŒŒì¼ì²¨ë¶€ ë° ëª¨ë¸ ë¡œë”©í›„) ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.**\")\n",
        "\n",
        "        with st.expander(\"**ì§ˆë¬¸ ì˜ˆì‹œ**\", expanded=False):\n",
        "            col71, col72, col73 =st.columns(3)\n",
        "            with col71:\n",
        "                st.code(\"what is the main topic of the attached article?\")\n",
        "                st.code(\"what is the main purpose of this document?\")\n",
        "            with col72:\n",
        "                st.code(\"summarize the attached article within 5 lines\")\n",
        "                st.code(\"Are there any risky conditions in the document?\")\n",
        "            with col73:\n",
        "                st.code(\"what is expected in the near future?\")\n",
        "                st.code(\"what is the best suggestion of the document?\")\n",
        "\n",
        "        chk1 = st.checkbox(\"ì‘ë‹µ í•œê¸€ ë²ˆì—­ í¬í•¨\", value=True)\n",
        "        st.session_state['replied'] = st.button(\"âš™ï¸ ì§ˆë¬¸ ì œì¶œ\", type='primary')\n",
        "\n",
        "\n",
        "        with st.spinner(\"ğŸ¤— ì¶”ë¡ ì¤‘...\"):\n",
        "            if st.session_state['replied']:\n",
        "                st.session_state['questions'].append(input100)\n",
        "                start_time = datetime.now()\n",
        "\n",
        "                response = st.session_state['dbqa']({'query': input100})\n",
        "                st.session_state['answer'].append(response[\"result\"])\n",
        "                st.session_state['src_docu1'].append(response[\"source_documents\"][0].page_content)\n",
        "                st.session_state['src_meta1'].append(response[\"source_documents\"][0].metadata[\"source\"])\n",
        "                try:\n",
        "                    st.session_state['src_docu2'].append(response[\"source_documents\"][1].page_content)\n",
        "                    st.session_state['src_meta2'].append(response[\"source_documents\"][1].metadata[\"source\"])\n",
        "                except:\n",
        "                    st.session_state['src_docu2'].append(\"\")\n",
        "                    st.session_state['src_meta2'].append(\"\")\n",
        "\n",
        "                st.markdown(f\"ğŸ˜† :blue[{st.session_state['answer'][-1]}]\")\n",
        "                end_time = datetime.now()\n",
        "                delta = calculate_time_delta(start_time, end_time)\n",
        "                st.warning(f\"â±ï¸ ì¶”ë¡ í›„ ì‘ë‹µì†Œìš”ì‹œê°„(ì´ˆ) : {delta}\")\n",
        "\n",
        "                try:\n",
        "                    if chk1:\n",
        "                        st.session_state['trans_answer'].append(trans(st.session_state['answer'][-1]))\n",
        "                        st.markdown(f\"ğŸ˜ƒ[ë²ˆì—­] :blue[{st.session_state['trans_answer'][-1]}]\")\n",
        "                    else:\n",
        "                        st.session_state['trans_answer'].append(\"\")\n",
        "                except:\n",
        "                    st.session_state['trans_answer'].append(\"\")\n",
        "\n",
        "                end_time = datetime.now()\n",
        "                delta = calculate_time_delta(start_time, end_time)\n",
        "                st.warning(f\"â±ï¸ ë²ˆì—­í›„ ì‘ë‹µì†Œìš”ì‹œê°„(ì´ˆ) : {delta}\")\n",
        "\n",
        "            with st.expander(\"âœ”ï¸ **ì „ì²´ ì§ˆì˜/ì‘ë‹µê²°ê³¼ ëª¨ìŒ (ë‹¤ìš´ë¡œë“œ)**\", expanded=True):\n",
        "                df = pd.DataFrame({\n",
        "                    \"ì§ˆë¬¸\":st.session_state['questions'],\n",
        "                    \"ì‘ë‹µ\":st.session_state['answer'],\n",
        "                    \"ë²ˆì—­ì‘ë‹µ\":st.session_state['trans_answer'],\n",
        "                    \"ê·¼ê±°ë¬¸ì¥1\":st.session_state['src_docu1'],\n",
        "                    \"ê·¼ê±°íŒŒì¼1\":st.session_state['src_meta1'],\n",
        "                    \"ê·¼ê±°ë¬¸ì¥2\":st.session_state['src_docu2'],\n",
        "                    \"ê·¼ê±°íŒŒì¼2\":st.session_state['src_meta2']})\n",
        "                st.dataframe(df, use_container_width=True)\n",
        "\n",
        "\n",
        "                @st.cache_data\n",
        "                def convert_df(df):\n",
        "                    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "                    return df.to_csv().encode('utf-8-sig')\n",
        "\n",
        "                csv = convert_df(df)\n",
        "\n",
        "                st.download_button(\n",
        "                    label=\"ğŸ—„ï¸ Download data as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name='answers.csv',\n",
        "                    mime='text/csv',\n",
        "                )\n",
        "    with tab902:\n",
        "        with st.expander(\"**ë²Œí¬ ì§ˆì˜/ì‘ë‹µ ë°©ë²• ì•ˆë‚´**\", expanded=True):\n",
        "            st.markdown('''\n",
        "            - ì§ˆë¬¸ ì²¨ë¶€ ì—‘ì…€ íŒŒì¼ì€ :blue[**.xlsx**] í˜•ì‹ìœ¼ë¡œ í•˜ê³ , 1í–‰ì— :red[**\"ì§ˆë¬¸\" ì¹¼ëŸ¼ëª…**] ìœ ì§€ (1ì—´ ë°ì´í„°)\n",
        "            - ì•„ë˜ ì‘ë‹µ ì¶”ë¡  ë²„íŠ¼ ëˆ„ë¥´ë©´, ì§ˆë¬¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì‘ë‹µí›„ ê²°ê³¼ë¥¼ ëª¨ì•„ì¤Œ (CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)\n",
        "            - í•œê¸€ ë²ˆì—­ì€ ì‹œê°„ë‹¹ API ìš”ì²­ ì´ˆê³¼ì‹œ ë¯¸ì‹¤ì‹œ ë  ìˆ˜ ìˆìŒ (ë²ˆì—­ì€ LLMì´ ì•„ë‹ˆë¼, ë³„ë„ Googletrans API ì‚¬ìš©)\n",
        "            - ê²€í†  ëŒ€ìƒ ë¬¸ì„œì˜ ì‚¬ì´ì¦ˆ, CPU-base Serving ë“±ìœ¼ë¡œ ì¶”ë¡ ì— ë‹¤ì†Œê°„ ì‹œê°„ì´ ì†Œìš”ë˜ëŠ” ì  ê³ ë ¤, ì ì‹¬ì‹œê°„ ë“±ì— ì´ìš© ê¶Œì¥(ì¶”ë¡ ì‹œê°„ ë‹¨ì¶• ë°©ë²•ì€ ì§€ì† ê²€í† ì¤‘)\n",
        "            ''')\n",
        "            st.image(\"09_ê°œë°œ/ê¹€ì¢…ë°°_llama2/images/ì²¨ë¶€ì˜ˆì‹œì´ë¯¸ì§€.png\", caption=\"ì—‘ì…€ ì§ˆë¬¸íŒŒì¼ ì˜ˆì‹œ ì´ë¯¸ì§€\")\n",
        "\n",
        "        uploaded_file = st.file_uploader(\"ì§ˆë¬¸ ëª©ë¡ ì—‘ì…€ íŒŒì¼ ì²¨ë¶€\")\n",
        "        if uploaded_file is not None:\n",
        "            t_df = pd.read_excel(uploaded_file)\n",
        "            ì§ˆë¬¸ëª©ë¡ = t_df[\"ì§ˆë¬¸\"]\n",
        "            ì§ˆë¬¸ê°œìˆ˜ = len(ì§ˆë¬¸ëª©ë¡)\n",
        "            st.markdown(f\"ğŸˆ **ì…ë ¥ ì§ˆë¬¸ ëª©ë¡ / :green[ì´ ì§ˆë¬¸ê°œìˆ˜ :{ì§ˆë¬¸ê°œìˆ˜}ê°œ]**\")\n",
        "            st.dataframe(ì§ˆë¬¸ëª©ë¡, use_container_width=True)\n",
        "\n",
        "        btn999= st.button(\"ğŸ” Bulk ì‘ë‹µ ì¶”ë¡ \", type=\"primary\")\n",
        "        with st.spinner(\"ë²Œí¬ ì‘ë‹µ ì¶”ë¡ ì¤‘...\"):\n",
        "            if btn999:\n",
        "\n",
        "                for idx, ì§ˆë¬¸ in enumerate(ì§ˆë¬¸ëª©ë¡):\n",
        "                    time.sleep(1)\n",
        "                    st.markdown(f\"[ì§ˆë¬¸{idx+1}] {ì§ˆë¬¸}\")\n",
        "                    st.session_state['questions'].append(ì§ˆë¬¸)\n",
        "                    start_time = datetime.now()\n",
        "                    start_time\n",
        "\n",
        "                    response = st.session_state['dbqa']({'query': ì§ˆë¬¸})\n",
        "\n",
        "                    st.session_state['answer'].append(response[\"result\"])\n",
        "                    st.session_state['src_docu1'].append(response[\"source_documents\"][0].page_content)\n",
        "                    st.session_state['src_meta1'].append(response[\"source_documents\"][0].metadata[\"source\"])\n",
        "                    st.session_state['src_docu2'].append(response[\"source_documents\"][1].page_content)\n",
        "                    st.session_state['src_meta2'].append(response[\"source_documents\"][1].metadata[\"source\"])\n",
        "\n",
        "                    st.markdown(f\"ğŸ˜† :blue[{st.session_state['answer'][-1]}]\")\n",
        "\n",
        "                    try:\n",
        "                        if chk1:\n",
        "                            st.session_state['trans_answer'].append(trans3(st.session_state['answer'][-1]))\n",
        "                            st.markdown(f\"ğŸ˜ƒ[ë²ˆì—­] :blue[{st.session_state['trans_answer'][-1]}]\")\n",
        "                        else:\n",
        "                            st.session_state['trans_answer'].append(\"\")\n",
        "                    except:\n",
        "                        st.session_state['trans_answer'].append(\"\")\n",
        "\n",
        "                    end_time = datetime.now()\n",
        "                    delta = calculate_time_delta(start_time, end_time)\n",
        "                    st.warning(f\"â±ï¸ ì‘ë‹µì†Œìš”ì‹œê°„(ì´ˆ) : {delta}\")\n",
        "\n",
        "                with st.expander(\"âœ”ï¸ **ì „ì²´ ì§ˆì˜/ì‘ë‹µê²°ê³¼ ëª¨ìŒ (ë‹¤ìš´ë¡œë“œ)**\", expanded=True):\n",
        "                    df = pd.DataFrame({\n",
        "                        \"ì§ˆë¬¸\":st.session_state['questions'],\n",
        "                        \"ì‘ë‹µ\":st.session_state['answer'],\n",
        "                        \"ë²ˆì—­ì‘ë‹µ\":st.session_state['trans_answer'],\n",
        "                        \"ê·¼ê±°ë¬¸ì¥1\":st.session_state['src_docu1'],\n",
        "                        \"ê·¼ê±°íŒŒì¼1\":st.session_state['src_meta1'],\n",
        "                        \"ê·¼ê±°ë¬¸ì¥2\":st.session_state['src_docu2'],\n",
        "                        \"ê·¼ê±°íŒŒì¼2\":st.session_state['src_meta2']})\n",
        "                    st.dataframe(df, use_container_width=True)\n",
        "\n",
        "\n",
        "                    @st.cache_data\n",
        "                    def convert_df(df):\n",
        "                        # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "                        return df.to_csv().encode('utf-8-sig')\n",
        "\n",
        "                    csv = convert_df(df)\n",
        "\n",
        "                    st.download_button(\n",
        "                        label=\"ğŸ—„ï¸ Download data as CSV\",\n",
        "                        data=csv,\n",
        "                        file_name='bulk_answers.csv',\n",
        "                        mime='text/csv',\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}